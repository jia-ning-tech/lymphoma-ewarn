<!-- BADGES_START -->

[ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç‰ˆ](README.zh-CN.md) ï½œ [â­ Star](https://github.com/jia-ning-tech/lymphoma-ewarn/stargazers) ï½œ [ï¿½ï¿½ Issues](https://github.com/jia-ning-tech/lymphoma-ewarn/issues)

![GitHub Repo stars](https://img.shields.io/github/stars/jia-ning-tech/lymphoma-ewarn?style=flat)
![GitHub issues](https://img.shields.io/github/issues/jia-ning-tech/lymphoma-ewarn?style=flat)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Release](https://img.shields.io/github/v/release/jia-ning-tech/lymphoma-ewarn?display_name=tag&sort=semver)

<!-- BADGES_END -->

<!-- TOC_START -->

## Table of Contents

- [Table of Contents](#table-of-contents)
- [TL;DR â€” Highlights](#tldr-highlights)
- [1. Abstract](#1-abstract)
- [2. Methods](#2-methods)
  - [2.1 Cohort & Feature Windows](#21-cohort-feature-windows)
  - [2.2 Models & Training](#22-models-training)
  - [2.3 Evaluation Metrics](#23-evaluation-metrics)
- [3. Results](#3-results)
  - [3.1 Discrimination (Window-level, Test)](#31-discrimination-window-level-test)
  - [3.2 Calibration](#32-calibration)
  - [Decision Thresholds (auto-generated)](#decision-thresholds-auto-generated)
  - [3.3 Lead Time (Test)](#33-lead-time-test)
  - [3.4 Interpretability (SHAP)](#34-interpretability-shap)
  - [3.5 Error Analysis (Test Example)](#35-error-analysis-test-example)
  - [3.6 Ablation (24h, 5-fold, 600 trees)](#36-ablation-24h-5-fold-600-trees)
  - [Keep-only (use only one group)](#keep-only-use-only-one-group)
  - [Drop-one (remove one group from the full set)](#drop-one-remove-one-group-from-the-full-set)
- [Ablation Studies](#ablation-studies)
  - [Ablation (h=24)](#ablation-h24)
- [4. Repository Layout & Project Structure](#4-repository-layout-project-structure)
- [Project Structure](#project-structure)
  - [Key Directories (auto-generated)](#key-directories-auto-generated)
  - [Full Tree (auto-generated)](#full-tree-auto-generated)
- [5. How to Reproduce](#5-how-to-reproduce)
  - [5.1 Environment](#51-environment)
  - [5.2 End-to-End Steps](#52-end-to-end-steps)
- [6. Repository Guide](#6-repository-guide)
- [7. Roadmap](#7-roadmap)
- [8. Acknowledgements & Disclaimer](#8-acknowledgements-disclaimer)
- [9. Limitations](#9-limitations)
- [10. Ethics & Data Access](#10-ethics-data-access)
- [11. License & Citation](#11-license-citation)
- [Decision Curve Analysis (DCA)](#decision-curve-analysis-dca)
  - [Decision Curve Analysis â€” h=24h, split=val](#decision-curve-analysis-h24h-splitval)
  - [Decision Curve Analysis â€” h=24h, split=test](#decision-curve-analysis-h24h-splittest)
  - [Decision Curve Analysis â€” h=48h, split=val](#decision-curve-analysis-h48h-splitval)
  - [Decision Curve Analysis â€” h=48h, split=test](#decision-curve-analysis-h48h-splittest)

<!-- TOC_END -->
<!-- Badges / Shields -->

<p align="center">
  <img alt="Python" src="https://img.shields.io/badge/Python-3.10%2B-blue?logo=python" />
  <img alt="scikit-learn" src="https://img.shields.io/badge/scikit--learn-1.x-ff9900?logo=scikitlearn&logoColor=white" />
  <img alt="SHAP" src="https://img.shields.io/badge/Explainability-SHAP-8A2BE2" />
  <img alt="Calibration" src="https://img.shields.io/badge/Calibration-Isotonic%20%7C%20Sigmoid-2aa198" />
  <img alt="CI" src="https://img.shields.io/badge/Status-Research%20Prototype-lightgrey" />
  <img alt="PRs" src="https://img.shields.io/badge/PRs-welcome-brightgreen" />
  <img alt="Love" src="https://img.shields.io/badge/Made%20with-%E2%9D%A4%EF%B8%8F-red" />
  <img alt="License" src="https://img.shields.io/badge/License-MIT-informational" />
</p>

<h1 align="center">Lymphoma-EWARN: Early Warning for Deterioration in ICU Lymphoma Patients</h1>

<p align="center">
  <em>Window-level risk prediction with lead time, stay-level aggregation, post-hoc calibration, SHAP interpretability, error analysis, and ablation studies.</em><br/>
  <a href="README.zh-CN.md">ä¸­æ–‡è¯´æ˜ï¼ˆChinese versionï¼‰</a>
</p>

---

## TL;DR â€” Highlights

* **Two horizons:** 24h & 48h early-warning windows
* **Discrimination (test):** AUROC â‰ˆ **0.79** (24h) / **0.81** (48h); AP â‰ˆ **0.14** / **0.29**
* **Lead time (test):** median â‰ˆ **39.83h (24h model)** / **34.35h (48h model)**
* **Post-hoc calibration:** Isotonic / Sigmoid; ECE tracked at window & stay levels
* **Interpretability:** SHAP global & individual explanations
* **Error analysis:** FP/FN cohorts + top-K windows for review
* **Ablation:** feature-group contributions (vitals / labs / vent / others)

---

## 1. Abstract

Timely detection of clinical deterioration among ICU lymphoma patients is challenging due to sparse, noisy, and heterogeneous signals. We develop **Lymphoma-EWARN**, a practical early-warning system that ingests engineered window-level features and outputs next-24h/48h risk scores. We evaluate both **window** and **stay** levels, quantify **lead time**, apply **post-hoc calibration**, provide **SHAP** explanations, perform **error analysis**, and conduct **ablation** on feature groups. Results indicate reliable discrimination and clinically meaningful lead time, paving the way for shadow deployment and standardized monitoring.

---

## 2. Methods

### 2.1 Cohort & Feature Windows

* Windows: **60,593** rows (`data_interim/trainset_hXX.parquet`)
* ICU stays: **721**
* Window positive rate (test): **2.72% (24h)** / **3.87% (48h)**
* Stay positive rate: **15.53%**
* Median windows per stay: **52** (p10â€“p90: 19â€“163)
* Time span per stay (median): **51h**

<details>
<summary>How these numbers were produced</summary>

```bash
python -m src.cli.cohort_stats --horizon 24
python -m src.cli.cohort_stats --horizon 48
# Outputs:
# outputs/reports/cohort_stats_h24_all.json
# outputs/reports/cohort_stats_h48_all.json
# outputs/reports/cohort_missingness_hXX_all.csv
# outputs/reports/cohort_numeric_summary_hXX_all.csv
```

</details>

### 2.2 Models & Training

* **Estimator**: `RandomForestClassifier` (e.g., `n_estimators=600`, `class_weight="balanced_subsample"`)
* **Preprocessing**: `SimpleImputer` (mean) within a sklearn `Pipeline`
* **Calibration**: Isotonic or Sigmoid (Platt), applied post-hoc
* **Evaluation splits**: `val`, `test` (window-level); aggregated to stay-level via **max probability** across windows per stay

### 2.3 Evaluation Metrics

* **Window-level**: AUROC, Average Precision (AP), Brier score, Expected Calibration Error (ECE)
* **Stay-level**: Precision / Recall / F1 @ chosen threshold (fixed or alert-rate target)
* **Lead time**: hours from **first alert** to **first event** per stay

---

## 3. Results

### 3.1 Discrimination (Window-level, Test)

| Horizon |      AUROC |         AP | Curves                                                                            |
| ------- | ---------: | ---------: | --------------------------------------------------------------------------------- |
| 24h     | **0.7903** | **0.1372** | ROC â†’ `outputs/figures/roc_h24_test.png` Â· PR â†’ `outputs/figures/pr_h24_test.png` |
| 48h     | **0.8121** | **0.2881** | ROC â†’ `outputs/figures/roc_h48_test.png` Â· PR â†’ `outputs/figures/pr_h48_test.png` |

```bash
python -m src.cli.plot_curves --horizon 24 --split test
python -m src.cli.plot_curves --horizon 48 --split test
```




<div align="center">
  <img src="docs/figures/roc_h24_test.png" alt="ROC 24h" width="45%"/>
  <img src="docs/figures/pr_h24_test.png"  alt="PR 24h"  width="45%"/><br/><br/>
  <img src="docs/figures/roc_h48_test.png" alt="ROC 48h" width="45%"/>
  <img src="docs/figures/pr_h48_test.png"  alt="PR 48h"  width="45%"/>
</div>


### 3.2 Calibration

**Window-level (test):**

| Horizon |      Brier |        ECE | Figures                                                                                                   |
| ------- | ---------: | ---------: | --------------------------------------------------------------------------------------------------------- |
| 24h     | **0.0497** | **0.0284** | `outputs/figures/calibration_h24_test_window.png`, `outputs/figures/calibration_hist_h24_test_window.png` |
| 48h     | **0.0747** | **0.0478** | `outputs/figures/calibration_h48_test_window.png`, `outputs/figures/calibration_hist_h48_test_window.png` |

**Stay-level (test):**

| Horizon |      Brier |        ECE | Notes             |
| ------- | ---------: | ---------: | ----------------- |
| 24h     | **0.1768** | **0.1506** | Max-prob per stay |
| 48h     | **0.1595** | **0.1350** | Max-prob per stay |

```bash
# Window-level
python -m src.cli.calibration_plot --horizon 24 --split test --bins 20 --strategy uniform
python -m src.cli.calibration_plot --horizon 48 --split test --bins 20 --strategy uniform
# Stay-level
python -m src.cli.calibration_plot --horizon 24 --split test --bins 20 --strategy uniform --stay_level
python -m src.cli.calibration_plot --horizon 48 --split test --bins 20 --strategy uniform --stay_level
```

<!-- THRESHOLDS_START -->

### Decision Thresholds (auto-generated)

| Horizon | Method   | Chosen Threshold | Source JSON |
|:-------:|:--------:|:----------------:|:------------|
| 24h | isotonic | **0.0577** | `outputs/reports/posthoc_calibration_h24_isotonic.json` |
| 24h | sigmoid | **0.0369** | `outputs/reports/posthoc_calibration_h24_sigmoid.json` |
| 48h | isotonic | **0.0544** | `outputs/reports/posthoc_calibration_h48_isotonic.json` |
| 48h | sigmoid | **0.0355** | `outputs/reports/posthoc_calibration_h48_sigmoid.json` |

<!-- THRESHOLDS_END -->




### 3.3 Lead Time (Test)

| Horizon |  n | Mean (h) | Median (h) |  P10 |  P25 |   P75 |   P90 |   Max |
| ------- | -: | -------: | ---------: | ---: | ---: | ----: | ----: | ----: |
| 48h     | 13 |    30.91 |      34.35 | 0.84 | 6.98 | 52.25 | 57.50 | 72.25 |
| 24h     |  9 |    34.81 |      39.83 | 0.51 | 2.00 | 54.50 | 61.05 | 72.25 |

```bash
python -m src.cli.leadtime_plot --horizon 48 --split test --threshold 0.24142504229084366
python -m src.cli.leadtime_plot --horizon 24 --split test --threshold 0.1205866239132141
# Figures:
# outputs/figures/leadtime_hist_hXX_test_thr*.png
# outputs/figures/leadtime_box_hXX_test_thr*.png
```

### 3.4 Interpretability (SHAP)

* Global: `outputs/figures/shap_global_beeswarm_h48_test.png`, `outputs/figures/shap_global_bar_h48_test.png`, CSV: `outputs/reports/shap_values_top_h48_test.csv`
* Individual top-K explanations are also exported (see CLI)

```bash
python -m src.cli.shap_explain --horizon 48 --split test --top_n 200 --top_k_individual 5
python -m src.cli.shap_explain --horizon 24 --split test --top_n 200 --top_k_individual 5
```

<!-- FI_START -->
## Feature importance

> We report permutation importance (mean Î”AUC over repeats). SHAP is currently unavailable due to model wrapper; will be added later.

### é¢„æµ‹æå‰çª— h=24 â€” validation

![Feature importance â€” h24 val](outputs/figures/fi_forest_h24_val.png)

| Feature | SHAP mean(|v|) | Perm mean | Perm std |
|---|---:|---:|---:|
| `peep__24h__count` | 0.00000 | 0.07928 | 0.00493 |
| `resp_rate__24h__count` | 0.00000 | 0.02508 | 0.00587 |
| `dbp__24h__count` | 0.00000 | 0.02164 | 0.00495 |
| `sbp__24h__count` | 0.00000 | 0.02109 | 0.00668 |
| `heart_rate__24h__count` | 0.00000 | 0.01949 | 0.00670 |
| `peep__6h__count` | 0.00000 | 0.01846 | 0.00923 |
| `hco3__24h__max` | 0.00000 | 0.01639 | 0.00088 |
| `hco3__24h__min` | 0.00000 | 0.01475 | 0.00270 |
| `spo2__24h__count` | 0.00000 | 0.01462 | 0.00264 |
| `hco3__24h__mean` | 0.00000 | 0.01456 | 0.00127 |
| `mbp__24h__count` | 0.00000 | 0.01282 | 0.00410 |
| `na__24h__mean` | 0.00000 | 0.01192 | 0.00538 |
| `na__24h__min` | 0.00000 | 0.01178 | 0.00284 |
| `temperature__24h__count` | 0.00000 | 0.01168 | 0.00628 |
| `cl__24h__mean` | 0.00000 | 0.01126 | 0.00388 |
| `cl__24h__max` | 0.00000 | 0.01015 | 0.00245 |
| `hco3__24h__std` | 0.00000 | 0.00990 | 0.00099 |
| `hco3__24h__last` | 0.00000 | 0.00983 | 0.00148 |
| `dbp__24h__max` | 0.00000 | 0.00959 | 0.00215 |
| `spo2__24h__mean` | 0.00000 | 0.00891 | 0.00449 |

### é¢„æµ‹æå‰çª— h=24 â€” test

![Feature importance â€” h24 test](outputs/figures/fi_forest_h24_test.png)

| Feature | SHAP mean(|v|) | Perm mean | Perm std |
|---|---:|---:|---:|
| `peep__24h__count` | 0.00000 | 0.04246 | 0.00154 |
| `cl__24h__mean` | 0.00000 | 0.00261 | 0.00034 |
| `peep__24h__std` | 0.00000 | 0.00246 | 0.00048 |
| `dbp__24h__mean` | 0.00000 | 0.00241 | 0.00116 |
| `cl__24h__min` | 0.00000 | 0.00207 | 0.00097 |
| `temperature__24h__mean` | 0.00000 | 0.00191 | 0.00035 |
| `heart_rate__6h__mean` | 0.00000 | 0.00173 | 0.00036 |
| `peep__24h__mean` | 0.00000 | 0.00168 | 0.00059 |
| `pt__24h__min` | 0.00000 | 0.00165 | 0.00040 |
| `lactate__24h__last` | 0.00000 | 0.00160 | 0.00070 |
| `spo2__24h__std` | 0.00000 | 0.00153 | 0.00046 |
| `na__6h__max` | 0.00000 | 0.00131 | 0.00012 |
| `peep__24h__max` | 0.00000 | 0.00130 | 0.00077 |
| `na__6h__mean` | 0.00000 | 0.00129 | 0.00017 |
| `heart_rate__24h__mean` | 0.00000 | 0.00120 | 0.00052 |
| `temperature__24h__max` | 0.00000 | 0.00113 | 0.00073 |
| `resp_rate__24h__std` | 0.00000 | 0.00112 | 0.00019 |
| `sbp__6h__min` | 0.00000 | 0.00111 | 0.00021 |
| `platelet__24h__mean` | 0.00000 | 0.00106 | 0.00090 |
| `pao2__24h__min` | 0.00000 | 0.00106 | 0.00018 |

### é¢„æµ‹æå‰çª— h=48 â€” validation

![Feature importance â€” h48 val](outputs/figures/fi_forest_h48_val.png)

| Feature | SHAP mean(|v|) | Perm mean | Perm std |
|---|---:|---:|---:|
| `peep__24h__count` | 0.00000 | 0.08343 | 0.00585 |
| `heart_rate__24h__count` | 0.00000 | 0.03088 | 0.00677 |
| `resp_rate__24h__count` | 0.00000 | 0.02665 | 0.00518 |
| `peep__6h__count` | 0.00000 | 0.02411 | 0.00649 |
| `sbp__24h__count` | 0.00000 | 0.02174 | 0.00532 |
| `ph__24h__min` | 0.00000 | 0.01863 | 0.00264 |
| `na__24h__mean` | 0.00000 | 0.01810 | 0.00643 |
| `spo2__24h__count` | 0.00000 | 0.01789 | 0.00408 |
| `dbp__24h__count` | 0.00000 | 0.01697 | 0.00680 |
| `mbp__24h__count` | 0.00000 | 0.01483 | 0.00472 |
| `ca__24h__max` | 0.00000 | 0.01478 | 0.00277 |
| `na__24h__min` | 0.00000 | 0.01420 | 0.00390 |
| `temperature__24h__count` | 0.00000 | 0.01020 | 0.00447 |
| `peep__24h__std` | 0.00000 | 0.00858 | 0.00394 |
| `hco3__24h__min` | 0.00000 | 0.00826 | 0.00059 |
| `spo2__24h__mean` | 0.00000 | 0.00803 | 0.00145 |
| `cl__24h__mean` | 0.00000 | 0.00791 | 0.00300 |
| `peep__24h__mean` | 0.00000 | 0.00710 | 0.00493 |
| `peep__24h__max` | 0.00000 | 0.00670 | 0.00362 |
| `cl__24h__min` | 0.00000 | 0.00649 | 0.00320 |

### é¢„æµ‹æå‰çª— h=48 â€” test

![Feature importance â€” h48 test](outputs/figures/fi_forest_h48_test.png)

| Feature | SHAP mean(|v|) | Perm mean | Perm std |
|---|---:|---:|---:|
| `peep__24h__count` | 0.00000 | 0.10095 | 0.00459 |
| `resp_rate__24h__max` | 0.00000 | 0.00641 | 0.00119 |
| `hgb__24h__min` | 0.00000 | 0.00563 | 0.00111 |
| `temperature__24h__count` | 0.00000 | 0.00520 | 0.00181 |
| `spo2__24h__mean` | 0.00000 | 0.00505 | 0.00183 |
| `platelet__24h__min` | 0.00000 | 0.00505 | 0.00126 |
| `bun__24h__max` | 0.00000 | 0.00483 | 0.00093 |
| `platelet__24h__max` | 0.00000 | 0.00421 | 0.00072 |
| `temperature__24h__mean` | 0.00000 | 0.00368 | 0.00065 |
| `peep__24h__std` | 0.00000 | 0.00358 | 0.00224 |
| `resp_rate__24h__mean` | 0.00000 | 0.00342 | 0.00223 |
| `ca__24h__mean` | 0.00000 | 0.00340 | 0.00242 |
| `lactate__24h__mean` | 0.00000 | 0.00302 | 0.00043 |
| `lactate__24h__last` | 0.00000 | 0.00299 | 0.00076 |
| `platelet__24h__mean` | 0.00000 | 0.00298 | 0.00103 |
| `creatinine__24h__min` | 0.00000 | 0.00294 | 0.00028 |
| `temperature__24h__min` | 0.00000 | 0.00283 | 0.00063 |
| `spo2__24h__count` | 0.00000 | 0.00272 | 0.00141 |
| `heart_rate__24h__count` | 0.00000 | 0.00269 | 0.00281 |
| `platelet__24h__last` | 0.00000 | 0.00243 | 0.00136 |
<!-- FI_END -->


### 3.5 Error Analysis (Test Example)

* Threshold by 10% alert rate (48h, raw): chosen thr â‰ˆ **0.0675**
* Stay-level @ thr=0.0675: **Precision=0.379**, **Recall=0.223**, **F1=0.281**
* Exports:

  * `outputs/reports/errors_fp_stay_h48_test_thr0.0675.parquet`
  * `outputs/reports/errors_fn_stay_h48_test_thr0.0675.parquet`
  * `outputs/reports/errors_fp_windows_top3_h48_test_thr0.0675.parquet`
  * `outputs/reports/errors_fn_windows_top3_h48_test_thr0.0675.parquet`

```bash
python -m src.cli.error_analysis --horizon 48 --split test --alert_rate 0.10
# or fix threshold
python -m src.cli.error_analysis --horizon 48 --split test --threshold 0.3346
# or use calibrated probs after:
python -m src.cli.posthoc_calibrate --horizon 48 --method isotonic --refit_threshold_rate 0.10
python -m src.cli.error_analysis --horizon 48 --split test --alert_rate 0.10 --calibrated isotonic
```

### 3.6 Ablation (24h, 5-fold, 600 trees)

* Baseline_all: AUROC â‰ˆ **0.797 Â± 0.023**; AP â‰ˆ **0.130 Â± 0.040**
* Drop vitals: AUROC â‰ˆ **0.771 Â± 0.028**; AP â‰ˆ **0.070 Â± 0.020**
* Ongoing: drop labs / vent / others â€¦

```bash
python -m src.cli.ablation_study --horizon 24 --folds 5 --n_estimators 600 --mode both
```

We quantify the contribution of feature groups using both **drop-one** and **keep-only** settings (5-fold CV, 600 trees, horizon=24h). Full CSV: `outputs/reports/ablation_h24.csv`.

### Keep-only (use only one group)
| Group   | AUROC (mean Â± sd) | AP (mean Â± sd) |
|--------|--------------------:|---------------:|
| **Vitals (n=98)** | **0.6604 Â± 0.0494** | **0.0602 Â± 0.0197** |
| **Labs (n=112)**  | **0.6662 Â± 0.0444** | **0.0488 Â± 0.0091** |
| **Vent (n=14)**   | **0.7719 Â± 0.0236** | **0.0686 Â± 0.0156** |
| **Others (n=148)**| **0.4985 Â± 0.0503** | **0.0296 Â± 0.0076** |

**Observation.** Using ventilator-related features alone surprisingly yields a relatively strong signal (AUROC ~0.77), while vitals/labs alone are moderate and â€œothersâ€ alone are weak.

### Drop-one (remove one group from the full set)
Baseline (all features): **AUROC 0.7974 Â± 0.0228**, **AP 0.1303 Â± 0.0398** (n_features=372)

| Removed Group | n_features (kept) | AUROC (mean Â± sd) | AP (mean Â± sd) |
|--------------|-------------------:|-------------------:|---------------:|
| **Vitals**   | 274 | **0.7711 Â± 0.0276** | **0.0696 Â± 0.0197** |
| **Labs**     | 260 | **0.7646 Â± 0.0274** | **0.1260 Â± 0.0447** |
| **Others**   | 224 | **0.8021 Â± 0.0262** | **0.1249 Â± 0.0360** |

**Interpretation.** Dropping **vitals** or **labs** degrades AUROC the most overall, suggesting both groups carry substantial signal when combined with others. Removing **others** barely hurts AUROC and may slightly fluctuate around baseline, implying their marginal utility is limited in this cohort and setup.

> Reproduce:
> ```bash
> python -m src.cli.ablation_study --horizon 24 --folds 5 --n_estimators 600 --mode both
> # Summary CSV â†’ outputs/reports/ablation_h24.csv
> ```

---

<!-- ABLATION:START -->
## Ablation Studies

This section unifies **keep-only** and **drop-one** ablation; all points are 5-fold CV **mean Â± std**.

### Ablation (h=24)

| Setting | Group | #Features | AUROC(meanÂ±std) | AP(meanÂ±std) |
|---|---:|---:|---:|---:|
| baseline_all | - | 372 | 0.7974 Â± 0.0228 | 0.1303 Â± 0.0398 |
| drop-one | labs | 260 | 0.7646 Â± 0.0274 | 0.1260 Â± 0.0447 |
| drop-one | others | 224 | 0.8021 Â± 0.0262 | 0.1249 Â± 0.0360 |
| drop-one | vent | 358 | 0.7225 Â± 0.0465 | 0.0773 Â± 0.0148 |
| drop-one | vitals | 274 | 0.7711 Â± 0.0276 | 0.0696 Â± 0.0197 |
| keep-only | labs | 112 | 0.6662 Â± 0.0444 | 0.0488 Â± 0.0091 |
| keep-only | others | 148 | 0.4985 Â± 0.0503 | 0.0296 Â± 0.0076 |
| keep-only | vent | 14 | 0.7719 Â± 0.0236 | 0.0686 Â± 0.0156 |
| keep-only | vitals | 98 | 0.6604 Â± 0.0494 | 0.0602 Â± 0.0197 |

<!-- ABLATION:END -->

---

## 4. Repository Layout & Project Structure

> The section below is **auto-generated** by the Makefile and can be refreshed with `make structure && make inject-structure`.
> The block is injected between anchors â€” please do not edit it by hand.

<!-- PROJECT_STRUCTURE:START -->
## Project Structure

### Key Directories (auto-generated)

| Path | Description | Exists | #Files |
|---|---|:---:|---:|
| `data_interim` | Intermediate/engineered feature tables for modeling. | yes | 13 |
| `data_raw` | Original/raw data (not tracked). | yes | 1 |
| `notebooks` | Exploratory notebooks (optional). | yes | 2 |
| `outputs` | Auto-generated artifacts. | yes | 158 |
| `outputs/figures` | Figures (ROC/PR, calibration, SHAP, lead-time, etc.). | yes | 31 |
| `outputs/models` | Trained model bundles (.joblib). | yes | 5 |
| `outputs/preds` | Inference & validation predictions (.parquet). | yes | 18 |
| `outputs/release` | Model release package for monitoring. | yes | 3 |
| `outputs/reports` | Metrics/tables used in paper & README (CSV/JSON/Parquet). | yes | 65 |
| `scripts` | Utility scripts (optional). | yes | 2 |
| `src` | Source code. | yes | 107 |
| `src/cli` | Command-line tools for training, evaluation, plots, release. | yes | 58 |

### Full Tree (auto-generated)

```text
â”œâ”€â”€ conf/
â”‚   â”œâ”€â”€ config.yaml
â”‚   â”œâ”€â”€ dictionaries.yaml
â”‚   â””â”€â”€ schema_features.yaml
â”œâ”€â”€ data_features/
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ data_interim/
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ cohort.parquet
â”‚   â”œâ”€â”€ events_first.csv
â”‚   â”œâ”€â”€ features_24h.parquet
â”‚   â”œâ”€â”€ features_6h.parquet
â”‚   â”œâ”€â”€ features_all.parquet
â”‚   â”œâ”€â”€ labels_all.parquet
â”‚   â”œâ”€â”€ labels_h24.parquet
â”‚   â”œâ”€â”€ labels_h48.parquet
â”‚   â”œâ”€â”€ trainset_h24.parquet
â”‚   â”œâ”€â”€ trainset_h48.parquet
â”‚   â”œâ”€â”€ ts_labs.parquet
â”‚   â””â”€â”€ ts_vitals.parquet
â”œâ”€â”€ data_raw/
â”‚   â”œâ”€â”€ hosp/
â”‚   â”‚   â”œâ”€â”€ admissions.csv
â”‚   â”‚   â”œâ”€â”€ d_hcpcs.csv
â”‚   â”‚   â”œâ”€â”€ d_icd_diagnoses.csv
â”‚   â”‚   â”œâ”€â”€ d_icd_procedures.csv
â”‚   â”‚   â”œâ”€â”€ d_labitems.csv
â”‚   â”‚   â”œâ”€â”€ diagnoses_icd.csv
â”‚   â”‚   â”œâ”€â”€ drgcodes.csv
â”‚   â”‚   â”œâ”€â”€ emar.csv
â”‚   â”‚   â”œâ”€â”€ emar_detail.csv
â”‚   â”‚   â”œâ”€â”€ hcpcsevents.csv
â”‚   â”‚   â”œâ”€â”€ labevents.csv
â”‚   â”‚   â”œâ”€â”€ microbiologyevents.csv
â”‚   â”‚   â”œâ”€â”€ omr.csv
â”‚   â”‚   â”œâ”€â”€ patients.csv
â”‚   â”‚   â”œâ”€â”€ pharmacy.csv
â”‚   â”‚   â”œâ”€â”€ poe.csv
â”‚   â”‚   â”œâ”€â”€ poe_detail.csv
â”‚   â”‚   â”œâ”€â”€ prescriptions.csv
â”‚   â”‚   â”œâ”€â”€ procedures_icd.csv
â”‚   â”‚   â”œâ”€â”€ provider.csv
â”‚   â”‚   â”œâ”€â”€ services.csv
â”‚   â”‚   â””â”€â”€ transfers.csv
â”‚   â”œâ”€â”€ icu/
â”‚   â”‚   â”œâ”€â”€ caregiver.csv
â”‚   â”‚   â”œâ”€â”€ chartevents.csv
â”‚   â”‚   â”œâ”€â”€ d_items.csv
â”‚   â”‚   â”œâ”€â”€ datetimeevents.csv
â”‚   â”‚   â”œâ”€â”€ icustays.csv
â”‚   â”‚   â”œâ”€â”€ ingredientevents.csv
â”‚   â”‚   â”œâ”€â”€ inputevents.csv
â”‚   â”‚   â”œâ”€â”€ outputevents.csv
â”‚   â”‚   â””â”€â”€ procedureevents.csv
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ env/
â”‚   â”œâ”€â”€ conda.yml
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_qc_glance.ipynb
â”‚   â””â”€â”€ 02_figures_for_paper.ipynb
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ alerts/
â”‚   â”‚   â”œâ”€â”€ smoke_h48_stay.csv
â”‚   â”‚   â”œâ”€â”€ smoke_h48_stay.parquet
â”‚   â”‚   â””â”€â”€ smoke_h48_window.parquet
â”‚   â”œâ”€â”€ artifacts/
â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â”œâ”€â”€ debug_chartevents_head.csv
â”‚   â”‚   â”œâ”€â”€ debug_chartevents_itemid.csv
â”‚   â”‚   â”œâ”€â”€ debug_chartevents_stay.csv
â”‚   â”‚   â”œâ”€â”€ debug_chartevents_stay_itemid_window.csv
â”‚   â”‚   â”œâ”€â”€ debug_labevents_hadm.csv
â”‚   â”‚   â”œâ”€â”€ debug_labevents_hadm_itemid_window.csv
â”‚   â”‚   â”œâ”€â”€ debug_labevents_head.csv
â”‚   â”‚   â”œâ”€â”€ debug_labevents_itemid.csv
â”‚   â”‚   â””â”€â”€ event_itemids.json
â”‚   â”œâ”€â”€ docs/
â”‚   â”‚   â””â”€â”€ model_card.md
â”‚   â”œâ”€â”€ figures/
â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â”œâ”€â”€ calibration_h24_test_stay.png
â”‚   â”‚   â”œâ”€â”€ calibration_h24_test_window.png
â”‚   â”‚   â”œâ”€â”€ calibration_h48_test_stay.png
â”‚   â”‚   â”œâ”€â”€ calibration_h48_test_window.png
â”‚   â”‚   â”œâ”€â”€ calibration_hist_h24_test_stay.png
â”‚   â”‚   â”œâ”€â”€ calibration_hist_h24_test_window.png
â”‚   â”‚   â”œâ”€â”€ calibration_hist_h48_test_stay.png
â”‚   â”‚   â”œâ”€â”€ calibration_hist_h48_test_window.png
â”‚   â”‚   â”œâ”€â”€ leadtime_box_h24_test_thr0.1206.png
â”‚   â”‚   â”œâ”€â”€ leadtime_box_h48_test_thr0.2414.png
â”‚   â”‚   â”œâ”€â”€ leadtime_hist_h24_test_thr0.1206.png
â”‚   â”‚   â”œâ”€â”€ leadtime_hist_h48_test_thr0.2414.png
â”‚   â”‚   â”œâ”€â”€ pr_h24_test.png
â”‚   â”‚   â”œâ”€â”€ pr_h48_test.png
â”‚   â”‚   â”œâ”€â”€ roc_h24_test.png
â”‚   â”‚   â”œâ”€â”€ roc_h48_test.png
â”‚   â”‚   â”œâ”€â”€ shap_global_bar_h24_test.png
â”‚   â”‚   â”œâ”€â”€ shap_global_bar_h48_test.png
â”‚   â”‚   â”œâ”€â”€ shap_global_beeswarm_h24_test.png
â”‚   â”‚   â”œâ”€â”€ shap_global_beeswarm_h48_test.png
â”‚   â”‚   â”œâ”€â”€ shap_waterfall_h24_test_rank1.png
â”‚   â”‚   â”œâ”€â”€ shap_waterfall_h24_test_rank2.png
â”‚   â”‚   â”œâ”€â”€ shap_waterfall_h24_test_rank3.png
â”‚   â”‚   â”œâ”€â”€ shap_waterfall_h24_test_rank4.png
â”‚   â”‚   â”œâ”€â”€ shap_waterfall_h24_test_rank5.png
â”‚   â”‚   â”œâ”€â”€ shap_waterfall_h48_test_rank1.png
â”‚   â”‚   â”œâ”€â”€ shap_waterfall_h48_test_rank2.png
â”‚   â”‚   â”œâ”€â”€ shap_waterfall_h48_test_rank3.png
â”‚   â”‚   â”œâ”€â”€ shap_waterfall_h48_test_rank4.png
â”‚   â”‚   â””â”€â”€ shap_waterfall_h48_test_rank5.png
â”‚   â”œâ”€â”€ logs/
â”‚   â”‚   â”œâ”€â”€ cli.build_cohort.log
â”‚   â”‚   â”œâ”€â”€ cli.events_labels.log
â”‚   â”‚   â”œâ”€â”€ cohort.log
â”‚   â”‚   â”œâ”€â”€ debug.extract.log
â”‚   â”‚   â”œâ”€â”€ demo.log
â”‚   â”‚   â”œâ”€â”€ events.detect.log
â”‚   â”‚   â”œâ”€â”€ events.dicts.log
â”‚   â”‚   â”œâ”€â”€ features.extract.log
â”‚   â”‚   â”œâ”€â”€ labeling.log
â”‚   â”‚   â”œâ”€â”€ lymphoma-ewarn.log
â”‚   â”‚   â”œâ”€â”€ quicktest.log
â”‚   â”‚   â”œâ”€â”€ readers.selftest.log
â”‚   â”‚   â”œâ”€â”€ timeidx.selftest.log
â”‚   â”‚   â”œâ”€â”€ to_parquet.log
â”‚   â”‚   â””â”€â”€ to_parquet.selftest.log
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â”œâ”€â”€ baseline_h24.joblib
â”‚   â”‚   â”œâ”€â”€ baseline_h48.joblib
â”‚   â”‚   â”œâ”€â”€ grouped_tvt_h24.joblib
â”‚   â”‚   â””â”€â”€ grouped_tvt_h48.joblib
â”‚   â”œâ”€â”€ preds/
â”‚   â”‚   â”œâ”€â”€ baseline_h24_test_preds.csv
â”‚   â”‚   â”œâ”€â”€ baseline_h48_test_preds.csv
â”‚   â”‚   â”œâ”€â”€ infer_h24.parquet
â”‚   â”‚   â”œâ”€â”€ infer_h48.parquet
â”‚   â”‚   â”œâ”€â”€ preds_h24_test.parquet
â”‚   â”‚   â”œâ”€â”€ preds_h24_test_cal_isotonic.parquet
â”‚   â”‚   â”œâ”€â”€ preds_h24_test_cal_sigmoid.parquet
â”‚   â”‚   â”œâ”€â”€ preds_h24_train.parquet
â”‚   â”‚   â”œâ”€â”€ preds_h24_val.parquet
â”‚   â”‚   â”œâ”€â”€ preds_h24_val_cal_isotonic.parquet
â”‚   â”‚   â”œâ”€â”€ preds_h24_val_cal_sigmoid.parquet
â”‚   â”‚   â”œâ”€â”€ preds_h48_test.parquet
â”‚   â”‚   â”œâ”€â”€ preds_h48_test_cal_isotonic.parquet
â”‚   â”‚   â”œâ”€â”€ preds_h48_test_cal_sigmoid.parquet
â”‚   â”‚   â”œâ”€â”€ preds_h48_train.parquet
â”‚   â”‚   â”œâ”€â”€ preds_h48_val.parquet
â”‚   â”‚   â”œâ”€â”€ preds_h48_val_cal_isotonic.parquet
â”‚   â”‚   â””â”€â”€ preds_h48_val_cal_sigmoid.parquet
â”‚   â”œâ”€â”€ release/
â”‚   â”‚   â””â”€â”€ h48_v0.1/
â”‚   â”‚       â”œâ”€â”€ config.json
â”‚   â”‚       â”œâ”€â”€ model.joblib
â”‚   â”‚       â””â”€â”€ release.json
â”‚   â”œâ”€â”€ reports/
â”‚   â”‚   â”œâ”€â”€ ablation_h24.csv
â”‚   â”‚   â”œâ”€â”€ alert_table_h24.csv
â”‚   â”‚   â”œâ”€â”€ alert_table_h48.csv
â”‚   â”‚   â”œâ”€â”€ baseline_h24.json
â”‚   â”‚   â”œâ”€â”€ baseline_h48.json
â”‚   â”‚   â”œâ”€â”€ calibration_points_h24_test_stay.csv
â”‚   â”‚   â”œâ”€â”€ calibration_points_h24_test_window.csv
â”‚   â”‚   â”œâ”€â”€ calibration_points_h48_test_stay.csv
â”‚   â”‚   â”œâ”€â”€ calibration_points_h48_test_window.csv
â”‚   â”‚   â”œâ”€â”€ calibration_summary_h24_test_stay.json
â”‚   â”‚   â”œâ”€â”€ calibration_summary_h24_test_window.json
â”‚   â”‚   â”œâ”€â”€ calibration_summary_h48_test_stay.json
â”‚   â”‚   â”œâ”€â”€ calibration_summary_h48_test_window.json
â”‚   â”‚   â”œâ”€â”€ cohort_missingness_h24_all.csv
â”‚   â”‚   â”œâ”€â”€ cohort_missingness_h48_all.csv
â”‚   â”‚   â”œâ”€â”€ cohort_numeric_summary_h24_all.csv
â”‚   â”‚   â”œâ”€â”€ cohort_numeric_summary_h48_all.csv
â”‚   â”‚   â”œâ”€â”€ cohort_stats_h24_all.json
â”‚   â”‚   â”œâ”€â”€ cohort_stats_h48_all.json
â”‚   â”‚   â”œâ”€â”€ error_summary_h48_test_thr0.0675.json
â”‚   â”‚   â”œâ”€â”€ error_summary_h48_test_thr0.3346.json
â”‚   â”‚   â”œâ”€â”€ errors_fn_stay_h48_test_thr0.0675.parquet
â”‚   â”‚   â”œâ”€â”€ errors_fn_stay_h48_test_thr0.3346.parquet
â”‚   â”‚   â”œâ”€â”€ errors_fn_windows_top3_h48_test_thr0.0675.parquet
â”‚   â”‚   â”œâ”€â”€ errors_fn_windows_top3_h48_test_thr0.3346.parquet
â”‚   â”‚   â”œâ”€â”€ errors_fp_stay_h48_test_thr0.0675.parquet
â”‚   â”‚   â”œâ”€â”€ errors_fp_stay_h48_test_thr0.3346.parquet
â”‚   â”‚   â”œâ”€â”€ errors_fp_windows_top3_h48_test_thr0.0675.parquet
â”‚   â”‚   â”œâ”€â”€ errors_fp_windows_top3_h48_test_thr0.3346.parquet
â”‚   â”‚   â”œâ”€â”€ errors_tn_stay_h48_test_thr0.0675.parquet
â”‚   â”‚   â”œâ”€â”€ errors_tn_stay_h48_test_thr0.3346.parquet
â”‚   â”‚   â”œâ”€â”€ errors_tp_stay_h48_test_thr0.0675.parquet
â”‚   â”‚   â”œâ”€â”€ errors_tp_stay_h48_test_thr0.3346.parquet
â”‚   â”‚   â”œâ”€â”€ feature_importance_h24.csv
â”‚   â”‚   â”œâ”€â”€ feature_importance_h48.csv
â”‚   â”‚   â”œâ”€â”€ infer_h24_summary.json
â”‚   â”‚   â”œâ”€â”€ infer_h48_summary.json
â”‚   â”‚   â”œâ”€â”€ leadtime_details_h24_test_thr0.1206.parquet
â”‚   â”‚   â”œâ”€â”€ leadtime_details_h48_test_thr0.2414.parquet
â”‚   â”‚   â”œâ”€â”€ leadtime_h24_test_thr0.1206.csv
â”‚   â”‚   â”œâ”€â”€ leadtime_h48_test_thr0.2414.csv
â”‚   â”‚   â”œâ”€â”€ posthoc_calibration_h24_isotonic.json
â”‚   â”‚   â”œâ”€â”€ posthoc_calibration_h24_sigmoid.json
â”‚   â”‚   â”œâ”€â”€ posthoc_calibration_h48_isotonic.json
â”‚   â”‚   â”œâ”€â”€ posthoc_calibration_h48_sigmoid.json
â”‚   â”‚   â”œâ”€â”€ pr_points_h24_test.csv
â”‚   â”‚   â”œâ”€â”€ pr_points_h48_test.csv
â”‚   â”‚   â”œâ”€â”€ report_h24_test.json
â”‚   â”‚   â”œâ”€â”€ report_h24_train.json
â”‚   â”‚   â”œâ”€â”€ report_h24_val.json
â”‚   â”‚   â”œâ”€â”€ report_h48_test.json
â”‚   â”‚   â”œâ”€â”€ report_h48_train.json
â”‚   â”‚   â”œâ”€â”€ report_h48_val.json
â”‚   â”‚   â”œâ”€â”€ roc_points_h24_test.csv
â”‚   â”‚   â”œâ”€â”€ roc_points_h48_test.csv
â”‚   â”‚   â”œâ”€â”€ shap_values_top_h24_test.csv
â”‚   â”‚   â”œâ”€â”€ shap_values_top_h48_test.csv
â”‚   â”‚   â”œâ”€â”€ stay_level_h24_thr0.0067.parquet
â”‚   â”‚   â”œâ”€â”€ stay_level_h24_thr0.5000.parquet
â”‚   â”‚   â”œâ”€â”€ stay_level_h48_thr0.0100.parquet
â”‚   â”‚   â”œâ”€â”€ stay_level_h48_thr0.5000.parquet
â”‚   â”‚   â”œâ”€â”€ summary_h24.json
â”‚   â”‚   â”œâ”€â”€ summary_h48.json
â”‚   â”‚   â”œâ”€â”€ thr_sweep_h24_test.csv
â”‚   â”‚   â””â”€â”€ thr_sweep_h48_test.csv
â”‚   â”œâ”€â”€ tables/
â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â””â”€â”€ weekly/
â”‚       â”œâ”€â”€ wk_h48_leadtime.parquet
â”‚       â”œâ”€â”€ wk_h48_leadtime_stats.json
â”‚       â”œâ”€â”€ wk_h48_stay.parquet
â”‚       â”œâ”€â”€ wk_h48_stay_metrics.json
â”‚       â””â”€â”€ wk_h48_window_metrics.json
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ summary_report.md
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ gen_structure.py
â”‚   â””â”€â”€ inject_structure.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ablation_study.py
â”‚   â”‚   â”œâ”€â”€ aggregate_by_stay.py
â”‚   â”‚   â”œâ”€â”€ build_cohort.py
â”‚   â”‚   â”œâ”€â”€ build_events_labels.py
â”‚   â”‚   â”œâ”€â”€ build_features.py
â”‚   â”‚   â”œâ”€â”€ calibration_plot.py
â”‚   â”‚   â”œâ”€â”€ cohort_stats.py
â”‚   â”‚   â”œâ”€â”€ cv_grouped.py
â”‚   â”‚   â”œâ”€â”€ debug_extract_sample.py
â”‚   â”‚   â”œâ”€â”€ deploy_batch.py
â”‚   â”‚   â”œâ”€â”€ error_analysis.py
â”‚   â”‚   â”œâ”€â”€ evaluate_all.py
â”‚   â”‚   â”œâ”€â”€ feature_importance.py
â”‚   â”‚   â”œâ”€â”€ finalize_release.py
â”‚   â”‚   â”œâ”€â”€ hparam_sweep.py
â”‚   â”‚   â”œâ”€â”€ infer_and_eval.py
â”‚   â”‚   â”œâ”€â”€ lead_time.py
â”‚   â”‚   â”œâ”€â”€ leadtime_plot.py
â”‚   â”‚   â”œâ”€â”€ make_splits.py
â”‚   â”‚   â”œâ”€â”€ make_threshold_profiles.py
â”‚   â”‚   â”œâ”€â”€ mk_readme.py
â”‚   â”‚   â”œâ”€â”€ plot_curves.py
â”‚   â”‚   â”œâ”€â”€ posthoc_calibrate.py
â”‚   â”‚   â”œâ”€â”€ shap_explain.py
â”‚   â”‚   â”œâ”€â”€ threshold_sweep.py
â”‚   â”‚   â”œâ”€â”€ train_24h.py
â”‚   â”‚   â”œâ”€â”€ train_48h.py
â”‚   â”‚   â”œâ”€â”€ train_baseline.py
â”‚   â”‚   â”œâ”€â”€ train_val_test.py
â”‚   â”‚   â””â”€â”€ weekly_monitor.py
â”‚   â”œâ”€â”€ cohort/
â”‚   â”‚   â””â”€â”€ build_cohort.py
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â””â”€â”€ assemble_training.py
â”‚   â”œâ”€â”€ eval/
â”‚   â”‚   â”œâ”€â”€ calibration.py
â”‚   â”‚   â”œâ”€â”€ dca.py
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â””â”€â”€ report.py
â”‚   â”œâ”€â”€ events/
â”‚   â”‚   â”œâ”€â”€ detect_events.py
â”‚   â”‚   â””â”€â”€ dictionaries.py
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ aggregate_windows.py
â”‚   â”‚   â”œâ”€â”€ build_feature_table.py
â”‚   â”‚   â”œâ”€â”€ derive_interventions.py
â”‚   â”‚   â”œâ”€â”€ extract_labs.py
â”‚   â”‚   â”œâ”€â”€ extract_outputs.py
â”‚   â”‚   â”œâ”€â”€ extract_vitals.py
â”‚   â”‚   â”œâ”€â”€ extract_vitals_labs.py
â”‚   â”‚   â”œâ”€â”€ extract_vitals_labs.py.bak
â”‚   â”‚   â”œâ”€â”€ extract_vitals_labs.py.bak2
â”‚   â”‚   â”œâ”€â”€ extract_vitals_labs.py.bak3
â”‚   â”‚   â”œâ”€â”€ extract_vitals_labs.py.bak_pandas
â”‚   â”‚   â””â”€â”€ windows.py
â”‚   â”œâ”€â”€ io/
â”‚   â”‚   â”œâ”€â”€ readers.py
â”‚   â”‚   â”œâ”€â”€ schema_check.py
â”‚   â”‚   â””â”€â”€ to_parquet.py
â”‚   â”œâ”€â”€ labeling/
â”‚   â”‚   â””â”€â”€ make_labels.py
â”‚   â”œâ”€â”€ modeling/
â”‚   â”‚   â”œâ”€â”€ calibrate.py
â”‚   â”‚   â”œâ”€â”€ models_gbm.py
â”‚   â”‚   â”œâ”€â”€ shap_tools.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ baseline.py
â”‚   â”œâ”€â”€ split/
â”‚   â”‚   â””â”€â”€ make_splits.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ log.py
â”‚   â”‚   â”œâ”€â”€ parallel.py
â”‚   â”‚   â””â”€â”€ timeidx.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_event_rules.py
â”‚   â”œâ”€â”€ test_time_leak.py
â”‚   â””â”€â”€ test_windows.py
â”œâ”€â”€ Makefile
â”œâ”€â”€ Makefile.bak.1761379016
â””â”€â”€ README.md
```
<!-- PROJECT_STRUCTURE:END -->

---

## 5. How to Reproduce

### 5.1 Environment

```bash
# Example
conda create -n ewarn python=3.10 -y
conda activate ewarn
pip install -r requirements.txt
```

### 5.2 End-to-End Steps

```bash
# Curves
python -m src.cli.plot_curves --horizon 24 --split test
python -m src.cli.plot_curves --horizon 48 --split test

# Calibration (window & stay)
python -m src.cli.calibration_plot --horizon 24 --split test --bins 20 --strategy uniform
python -m src.cli.calibration_plot --horizon 48 --split test --bins 20 --strategy uniform
python -m src.cli.calibration_plot --horizon 24 --split test --bins 20 --strategy uniform --stay_level
python -m src.cli.calibration_plot --horizon 48 --split test --bins 20 --strategy uniform --stay_level

# Lead-time
python -m src.cli.leadtime_plot --horizon 48 --split test --threshold 0.24142504229084366
python -m src.cli.leadtime_plot --horizon 24 --split test --threshold 0.1205866239132141

# Interpretability
python -m src.cli.shap_explain --horizon 48 --split test --top_n 200 --top_k_individual 5
python -m src.cli.shap_explain --horizon 24 --split test --top_n 200 --top_k_individual 5

# Post-hoc calibration & error analysis
python -m src.cli.posthoc_calibrate --horizon 24 --method isotonic --refit_threshold_rate 0.10
python -m src.cli.error_analysis --horizon 24 --split test --alert_rate 0.10 --calibrated isotonic

# Cohort stats
python -m src.cli.cohort_stats --horizon 24
python -m src.cli.cohort_stats --horizon 48
```

---

## 6. Repository Guide

* `src/` â€” source code
* `src/cli/` â€” command-line interfaces for training, evaluation, plots, release bundle
* `data_raw/` â€” original data (not tracked)
* `data_interim/` â€” engineered features and intermediate artifacts
* `outputs/` â€” auto-generated results

  * `outputs/models/` â€” trained model bundles (`.joblib`)
  * `outputs/preds/` â€” predictions (`.parquet`)
  * `outputs/reports/` â€” metrics/tables for paper & README
  * `outputs/figures/` â€” ROC/PR, calibration, SHAP, lead-time, etc.
  * `outputs/release/` â€” packaged artifacts for deployment/monitoring
* `notebooks/` â€” exploratory analyses (optional)
* `scripts/` â€” utilities (optional)

> For a fresh snapshot of the full tree, use the Makefile helpers to generate and inject the structure section.

---

## 7. Roadmap

* âœ… Curves, calibration, lead-time, SHAP, error tables
* âœ… Ablation with progress bars & ETA
* â³ Shadow run & standardized monitoring
* â³ Paper polishing and auto-syncing figures/tables
* â³ Multi-center generalization & fairness diagnostics

---

## 8. Acknowledgements & Disclaimer

We are grateful to our clinical collaborators and the open-source community (scikit-learn, SHAP). This repository is intended for **research use** only. Any clinical deployment requires rigorous validation, governance, and oversight.

> *With humility:* we see this as a starting pointâ€”not an endpointâ€”towards transparent, reliable early-warning tools that can one day assist clinicians and benefit patients.

> We know there is still much to improve. If you notice issues or have ideas, we sincerely welcome discussions and pull requests. Thank you for your patience and feedback. ğŸ™

---
## 9. Limitations

* Single-center cohort with lymphoma patients; generalizability to other centers/populations remains to be validated.
* Retrospective labeling and windowing may introduce time-alignment biases.
* Class imbalance is substantial; alert-rateâ€“based thresholding can still yield non-trivial false alarms at stay level.
* We only explored RandomForest in depth; stronger gradient-boosting or temporal models (e.g., XGBoost, LightGBM, RNN/Transformer) may further improve performance.

## 10. Ethics & Data Access

This work uses MIMIC-style ICU data under the corresponding data use agreement. Access requires credentialed researchers to complete the datasetâ€™s required training and approval process. **We do not redistribute raw patient data.** All experiments in this repo operate on derived, de-identified tables generated locally. For any clinical deployment, institutional review, safety assessments, and governance are mandatory.

---

## 11. License & Citation

**License.** Released under the MIT License (see `LICENSE`).

**Citation.** If you use this repository, please cite:

```bibtex
@misc{lymphoma_ewarn_2025,
  title        = {Lymphoma-EWARN: Early Warning for Clinical Deterioration in ICU Lymphoma Patients},
  author       = {Jia-Ning Tech and collaborators},
  year         = {2025},
  publisher    = {GitHub},
  howpublished = {\url{https://github.com/jia-ning-tech/lymphoma-ewarn}}
}

```
---

**Language:** [English](README.md) | [ä¸­æ–‡](README.zh-CN.md)

---




<!-- DCA_START -->

### Decision Curve Analysis (h=24h, split=test)

![DCA (raw probability)](outputs/figures/dca_h24_test.png)

![DCA (calibrated: isotonic)](outputs/figures/dca_h24_test_cal_isotonic.png)

![DCA (calibrated: sigmoid)](outputs/figures/dca_h24_test_cal_sigmoid.png)


### Decision Curve Analysis (h=48h, split=test)

![DCA (raw probability)](outputs/figures/dca_h48_test.png)

![DCA (calibrated: isotonic)](outputs/figures/dca_h48_test_cal_isotonic.png)

![DCA (calibrated: sigmoid)](outputs/figures/dca_h48_test_cal_sigmoid.png)

<!-- DCA_END -->
